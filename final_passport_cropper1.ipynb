{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247299cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"ViT-B-32\"\n",
    "pretrained = \"laion2b_s34b_b79k\"   \n",
    "model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained)\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "\n",
    "model = model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e58f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = [\n",
    "    \"an open passport showing the identification page\",\n",
    "    \"a passport data page with photo and text\",\n",
    "    \"a passport biodata page\",\n",
    "    \"a passport identity page\",\n",
    "    \"a photo ID page in a passport\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293dddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows_ar(H, W,\n",
    "                        area_fracs=(0.45, 0.38, 0.32, 0.26, 0.22),\n",
    "                        ratios=(1.25, 1.35, 1.45, 1.6, 1.0),\n",
    "                        stride=0.22):\n",
    "    \"\"\"\n",
    "    Windows by area fraction + aspect ratios.\n",
    "    ratio = win_w / win_h\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    for a in area_fracs:\n",
    "        for r in ratios:\n",
    "            win_w = int(np.sqrt(a * W * H * r))\n",
    "            win_h = int(np.sqrt(a * W * H / r))\n",
    "\n",
    "            if win_w < 200 or win_h < 200 or win_w > W or win_h > H:\n",
    "                continue\n",
    "\n",
    "            sx = max(1, int(win_w * stride))\n",
    "            sy = max(1, int(win_h * stride))\n",
    "\n",
    "            for y0 in range(0, H - win_h + 1, sy):\n",
    "                for x0 in range(0, W - win_w + 1, sx):\n",
    "                    windows.append((x0, y0, x0 + win_w, y0 + win_h))\n",
    "    return windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701beaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def clip_score_bgr(img_bgr, prompts):\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(rgb)\n",
    "\n",
    "    image = preprocess(pil).unsqueeze(0).to(device)\n",
    "    text = tokenizer(prompts).to(device)\n",
    "\n",
    "    image_feat = model.encode_image(image)\n",
    "    text_feat  = model.encode_text(text)\n",
    "\n",
    "    image_feat = image_feat / image_feat.norm(dim=-1, keepdim=True)\n",
    "    text_feat  = text_feat  / text_feat.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    sims = (image_feat @ text_feat.T).squeeze(0)  \n",
    "    return float(sims.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_keep_aspect(img, max_w=900):\n",
    "    h, w = img.shape[:2]\n",
    "    if w <= max_w:\n",
    "        return img, 1.0\n",
    "    scale = max_w / w\n",
    "    new_size = (int(w * scale), int(h * scale))\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_AREA), scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c578a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_data_page_zero_shot(img_bgr, prompts=PROMPTS, target_ratio=1.4):\n",
    "    H, W = img_bgr.shape[:2]\n",
    "\n",
    "    small, scale = resize_keep_aspect(img_bgr, max_w=900)\n",
    "    Hs, Ws = small.shape[:2]\n",
    "\n",
    "    windows = generate_windows_ar(Hs, Ws)\n",
    "\n",
    "    if not windows:\n",
    "        return img_bgr, {\"reason\": \"no_windows_generated\"}\n",
    "\n",
    "    best = None\n",
    "    for (x0, y0, x1, y1) in windows:\n",
    "        crop = small[y0:y1, x0:x1]\n",
    "        s = clip_score_bgr(crop, prompts)\n",
    "\n",
    "        # penalties\n",
    "        area = (x1-x0) * (y1-y0) / (Hs * Ws)\n",
    "        r = (x1-x0) / ((y1-y0) + 1e-6)\n",
    "        ar_pen = abs(np.log(r / target_ratio))          # 0 when perfect\n",
    "        s_adj = s - 0.03 * area - 0.08 * ar_pen         \n",
    "\n",
    "        if (best is None) or (s_adj > best[\"score_adj\"]):\n",
    "            best = {\"x0\":x0,\"y0\":y0,\"x1\":x1,\"y1\":y1,\"score\":s,\"score_adj\":s_adj,\"area\":area,\"ratio\":r}\n",
    "\n",
    "    inv = 1.0 / scale\n",
    "    x0 = int(best[\"x0\"] * inv); y0 = int(best[\"y0\"] * inv)\n",
    "    x1 = int(best[\"x1\"] * inv); y1 = int(best[\"y1\"] * inv)\n",
    "\n",
    "    x0 = max(0, x0); y0 = max(0, y0)\n",
    "    x1 = min(W, x1); y1 = min(H, y1)\n",
    "\n",
    "    crop_best = img_bgr[y0:y1, x0:x1].copy()\n",
    "\n",
    "    debug = {\n",
    "        \"bbox\": (x0, y0, x1, y1),\n",
    "        \"score\": float(best[\"score\"]),\n",
    "        \"score_adj\": float(best[\"score_adj\"]),\n",
    "        \"area_frac\": float(best[\"area\"]),\n",
    "        \"win_ratio\": float(best[\"ratio\"]),\n",
    "        \"num_windows\": len(windows),\n",
    "    }\n",
    "    return crop_best, debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba910e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_bbox_asym(bbox, W, H,\n",
    "                     pad_left=0.02, pad_right=0.55,\n",
    "                     pad_top=0.00,  pad_bottom=2.10,\n",
    "                     shift_x=0.02,  shift_y=0.48):\n",
    "    \"\"\"\n",
    "    pad_* are fractions of bbox width/height.\n",
    "    shift_* moves the box right/down by a fraction of bbox width/height.\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    bw = x1 - x0\n",
    "    bh = y1 - y0\n",
    "\n",
    "    # shift the bbox\n",
    "    dx = int(shift_x * bw)\n",
    "    dy = int(shift_y * bh)\n",
    "    x0 += dx; x1 += dx\n",
    "    y0 += dy; y1 += dy\n",
    "\n",
    "    # asymmetric padding\n",
    "    x0 = int(x0 - pad_left * bw)\n",
    "    x1 = int(x1 + pad_right * bw)\n",
    "    y0 = int(y0 - pad_top * bh)\n",
    "    y1 = int(y1 + pad_bottom * bh)\n",
    "\n",
    "    # clamp\n",
    "    x0 = max(0, x0); y0 = max(0, y0)\n",
    "    x1 = min(W, x1); y1 = min(H, y1)\n",
    "    return (x0, y0, x1, y1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_quad_points(pts):\n",
    "    pts = np.array(pts, dtype=np.float32)\n",
    "    s = pts.sum(axis=1)\n",
    "    diff = np.diff(pts, axis=1).reshape(-1)\n",
    "\n",
    "    tl = pts[np.argmin(s)]\n",
    "    br = pts[np.argmax(s)]\n",
    "    tr = pts[np.argmin(diff)]\n",
    "    bl = pts[np.argmax(diff)]\n",
    "\n",
    "    return np.array([tl, tr, br, bl], dtype=np.float32)\n",
    "\n",
    "def four_point_warp(image, quad, out_w=1000, out_h=700):\n",
    "    quad = order_quad_points(quad)\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [out_w - 1, 0],\n",
    "        [out_w - 1, out_h - 1],\n",
    "        [0, out_h - 1]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(quad, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (out_w, out_h))\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e582bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_to_page_boundary_threshold(crop_bgr):\n",
    "    gray = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Normalize + smooth\n",
    "    gray = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Invert so page content becomes foreground-ish\n",
    "    thr = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 35, 10\n",
    "    )\n",
    "\n",
    "    # Merge text blocks into one region (so the page becomes a big blob)\n",
    "    thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, np.ones((9,9), np.uint8), iterations=2)\n",
    "    thr = cv2.dilate(thr, np.ones((7,7), np.uint8), iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return crop_bgr, {\"refine\": \"no_contours\"}\n",
    "\n",
    "    # Biggest contour as page candidate\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    H, W = crop_bgr.shape[:2]\n",
    "\n",
    "    if area < 0.20 * (H * W):\n",
    "        # If too small, likely grabbed just text area; return original crop\n",
    "        return crop_bgr, {\"refine\": \"contour_too_small\", \"area\": float(area)}\n",
    "\n",
    "    rect = cv2.minAreaRect(cnt)                 # ((cx,cy),(w,h),angle)\n",
    "    box = cv2.boxPoints(rect).astype(np.float32)\n",
    "\n",
    "    warped = four_point_warp(crop_bgr, box, out_w=1000, out_h=700)\n",
    "    return warped, {\"refine\": \"minAreaRect_warped\", \"area\": float(area)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01490190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_trim_warp(warped, trim_top=0.10, trim_bottom=0.00):\n",
    "    h, w = warped.shape[:2]\n",
    "    y0 = int(h * trim_top)\n",
    "    y1 = int(h * (1.0 - trim_bottom))\n",
    "    return warped[y0:y1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcabbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"IMG_1298.jpeg\")\n",
    "H, W = img.shape[:2]\n",
    "\n",
    "region, dbg1 = locate_data_page_zero_shot(img)\n",
    "\n",
    "bbox2 = expand_bbox_asym(\n",
    "    dbg1[\"bbox\"], W, H,\n",
    "    pad_left=0.02, pad_right=0.55,\n",
    "    pad_top=0.00,  pad_bottom=1.90,   # <-- increase this\n",
    "    shift_x=0.02,  shift_y=0.48\n",
    ")\n",
    "\n",
    "x0,y0,x1,y1 = bbox2\n",
    "region2 = img[y0:y1, x0:x1].copy()\n",
    "\n",
    "page, dbg2 = refine_to_page_boundary_threshold(region2)\n",
    "\n",
    "page = post_trim_warp(page, trim_top=0.10, trim_bottom=0.00)\n",
    "\n",
    "print(\"Expanded bbox:\", bbox2)\n",
    "print(\"Refine:\", dbg2)\n",
    "\n",
    " #notebook display (matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "def show_bgr(bgr, title=\"\"):\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_bgr(region2, \"Selected region (expanded asym)\")\n",
    "show_bgr(page, \"Refined full page (threshold warp)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6fa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6ca7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
